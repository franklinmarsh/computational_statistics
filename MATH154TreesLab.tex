\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}



\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath}
\usepackage{flexisym}
\usepackage{titlesec}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


\title{Math 154 Tree-based Methods Lab}
\author{Roja, Franklin, Alejandra}
\maketitle

In addition to using the kaggle data, load the data set mtcars into R via the
command data(mtcars). Try to predict the fuel efficiency (mpg) via a regression tree, and try to predict the transmission type (automatic or manual) via a classification
tree.
You may want to compare the regression tree to a linear model.
plot(mtcars) will give you all the pairwise scatter plots. Notice that most of the
relationships with MPG are non-linear.

Additionally, R has a package called randomForest. The most useful function,
which implements the algorithm discussed in class, is of the same name. Compare
the classification rates for a random forest to that of a simple tree.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# install.packages("tree")}
\hlcom{# install.packages("randomForest")}
\hlcom{# install.packages('reprtree')}
\hlkwd{library}\hlstd{(tree)}
\hlkwd{library}\hlstd{(randomForest)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# randomForest 4.6-12}}

{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Type rfNews() to see new features/changes/bug fixes.}}\begin{alltt}
\hlkwd{library}\hlstd{(datasets)}
\hlcom{# library(reprtree)}

\hlkwd{data}\hlstd{(mtcars)}
\end{alltt}
\end{kframe}
\end{knitrout}


In order to predict the fuel efficiency we implemented a regression tree and  a linear regression model to later compare results. We divided the data into a training and test set. Since the sample size is only thirty-two, the two sets only had sixteen observations. One method we used to compare the performance of both models was residual sum of squares. We consistently found that predictions made with a linear regression model had a lower residual sum of squares than those made with a regression tree. It may be due to there only being three nodes and therefore, three averages which new observations can take on. 


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Regression Tree}
\hlstd{test.index} \hlkwb{=} \hlkwd{sample}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(mtcars)),}\hlkwd{nrow}\hlstd{(mtcars)}\hlopt{/}\hlnum{2} \hlstd{)}
\hlstd{training.index}\hlkwb{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(mtcars))[}\hlopt{-}\hlstd{test.index]}

\hlstd{test.data} \hlkwb{=} \hlstd{mtcars[test.index,]}
\hlstd{training.data} \hlkwb{=} \hlstd{mtcars[training.index,]}

\hlstd{cars.regression} \hlkwb{<-} \hlkwd{tree}\hlstd{(mpg} \hlopt{~} \hlstd{cyl}\hlopt{+}\hlstd{disp}\hlopt{+}\hlstd{hp}\hlopt{+}\hlstd{drat}\hlopt{+}\hlstd{wt}\hlopt{+}\hlstd{qsec}\hlopt{+}\hlstd{vs}\hlopt{+}\hlstd{am}\hlopt{+}\hlstd{gear}\hlopt{+}\hlstd{carb,} \hlkwc{data}\hlstd{=training.data)}
\hlkwd{plot}\hlstd{(cars.regression )}
\hlkwd{text}\hlstd{(cars.regression ,} \hlkwc{cex}\hlstd{=}\hlnum{.75}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-2-1} 
\begin{kframe}\begin{alltt}
\hlstd{my.prediction} \hlkwb{<-} \hlkwd{predict}\hlstd{(cars.regression, test.data)}

\hlcom{# find RSS }
\hlstd{residuals} \hlkwb{=} \hlstd{(test.data}\hlopt{$}\hlstd{mpg} \hlopt{-} \hlstd{my.prediction)}\hlopt{^}\hlnum{2}
\hlkwd{sum}\hlstd{(residuals}\hlopt{^}\hlnum{2}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 8133.442
\end{verbatim}
\begin{alltt}
\hlcom{# plot residuals }
\hlkwd{plot}\hlstd{(residuals)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-2-2} 
\begin{kframe}\begin{alltt}
\hlcom{# plot of actual and predictions}
\hlkwd{plot}\hlstd{(test.data}\hlopt{$}\hlstd{mpg,} \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{40}\hlstd{))}
\hlkwd{points}\hlstd{(my.prediction,} \hlkwc{col} \hlstd{=} \hlstr{'red'}\hlstd{)}
\hlkwd{legend}\hlstd{(}\hlnum{2}\hlstd{,} \hlnum{10}\hlstd{,} \hlkwc{legend}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"Actual"}\hlstd{,} \hlstr{"Predictions"}\hlstd{),}
       \hlkwc{col}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"black"}\hlstd{,} \hlstr{"red"}\hlstd{),}\hlkwc{pch} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-2-3} 
\begin{kframe}\begin{alltt}
\hlcom{#####}
\hlcom{# Comparing to a Linear model }
\hlcom{#plot(mtcars)}

\hlstd{cars.lm} \hlkwb{<-} \hlkwd{lm} \hlstd{( mpg} \hlopt{~} \hlstd{cyl}\hlopt{+}\hlstd{disp}\hlopt{+}\hlstd{hp}\hlopt{+}\hlstd{drat}\hlopt{+}\hlstd{wt}\hlopt{+}\hlstd{qsec}\hlopt{+}\hlstd{vs}\hlopt{+}\hlstd{am}\hlopt{+}\hlstd{gear}\hlopt{+}\hlstd{carb,} \hlkwc{data}\hlstd{= training.data)}
\hlstd{prediction.lm} \hlkwb{<-} \hlkwd{predict}\hlstd{(cars.lm, test.data)}
\hlcom{# find RSS }
\hlstd{residuals.lm} \hlkwb{=} \hlstd{(test.data}\hlopt{$}\hlstd{mpg} \hlopt{-} \hlstd{prediction.lm)}\hlopt{^}\hlnum{2}
\hlkwd{sum}\hlstd{(residuals.lm}\hlopt{^}\hlnum{2}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 24604.64
\end{verbatim}
\begin{alltt}
\hlcom{# plot residuals }
\hlkwd{plot}\hlstd{(residuals.lm,} \hlkwc{main} \hlstd{=} \hlstr{"Residuals from Linear Model"}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-2-4} 
\begin{kframe}\begin{alltt}
\hlcom{# plot of actual and predictions}
\hlkwd{plot}\hlstd{(test.data}\hlopt{$}\hlstd{mpg,} \hlkwc{main}\hlstd{=} \hlstr{"Plot of Actual vs. Prediction from Linear Model"}\hlstd{,} \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{40}\hlstd{))}
\hlkwd{points}\hlstd{(prediction.lm,} \hlkwc{col} \hlstd{=} \hlstr{'red'}\hlstd{)}
\hlkwd{legend}\hlstd{(}\hlnum{2}\hlstd{,} \hlnum{10}\hlstd{,} \hlkwc{legend}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"Actual"}\hlstd{,} \hlstr{"Predictions"}\hlstd{),}
       \hlkwc{col}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"black"}\hlstd{,} \hlstr{"red"}\hlstd{),}\hlkwc{pch} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-2-5} 
\begin{kframe}\begin{alltt}
\hlcom{# to do: }
\hlcom{# reduce the number f variables? stepwise regression?}
\hlcom{# consider nonlinear relationships }
\end{alltt}
\end{kframe}
\end{knitrout}


We used Classification and Random Forests to predict the transmission type of a car. The classification tree had three terminal nodes and used \textit{weight} and \textit{mpg} in the tree. Since the response variable was binary we calculated the proportion of times each method predicted  accurately. The accuracy of the predictions from both methods were about the same.  

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Classification Tree}
\hlcom{# Use a classification tree to predict transmission type of car}
\hlcom{# Transmission (0 = automatic, 1 = manual)}

\hlstd{cars.class}\hlkwb{<-}\hlkwd{tree}\hlstd{(am} \hlopt{~} \hlstd{mpg}\hlopt{+}\hlstd{cyl}\hlopt{+}\hlstd{disp}\hlopt{+}\hlstd{hp}\hlopt{+}\hlstd{drat}\hlopt{+}\hlstd{wt}\hlopt{+}\hlstd{qsec}\hlopt{+}\hlstd{vs}\hlopt{+}\hlstd{gear}\hlopt{+}\hlstd{carb,} \hlkwc{data}\hlstd{=training.data)}
\hlkwd{summary}\hlstd{(cars.class)}
\end{alltt}
\begin{verbatim}
## 
## Regression tree:
## tree(formula = am ~ mpg + cyl + disp + hp + drat + wt + qsec + 
##     vs + gear + carb, data = training.data)
## Variables actually used in tree construction:
## [1] "wt"
## Number of terminal nodes:  2 
## Residual mean deviance:  0 = 0 / 14 
## Distribution of residuals:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       0       0       0       0       0       0
\end{verbatim}
\begin{alltt}
\hlkwd{plot}\hlstd{(cars.class)}
\hlkwd{text}\hlstd{(cars.class)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-3-1} 
\begin{kframe}\begin{alltt}
\hlstd{my.prediction.class} \hlkwb{<-} \hlkwd{predict}\hlstd{(cars.class, test.data)}
\hlkwd{plot}\hlstd{(test.data}\hlopt{$}\hlstd{am,} \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{2.1}\hlstd{))}
\hlkwd{points}\hlstd{(my.prediction.class,}\hlkwc{col} \hlstd{=} \hlstr{'purple'}\hlstd{,} \hlkwc{pch} \hlstd{=} \hlstr{"."}\hlstd{)}
\hlkwd{legend}\hlstd{(}\hlnum{2}\hlstd{,} \hlnum{2}\hlstd{,} \hlkwc{legend}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"Actual"}\hlstd{,} \hlstr{"Predictions"}\hlstd{),}
       \hlkwc{col}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"black"}\hlstd{,} \hlstr{"purple"}\hlstd{),}\hlkwc{pch} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-3-2} 
\begin{kframe}\begin{alltt}
\hlcom{# how many incorrect predictions }
\hlstd{incorrect.predict} \hlkwb{=} \hlkwd{sum}\hlstd{(}\hlkwd{abs}\hlstd{(my.prediction.class} \hlopt{-} \hlstd{test.data}\hlopt{$}\hlstd{am)} \hlopt{>} \hlnum{.5}\hlstd{)}
\hlstd{incorrect.predict}
\end{alltt}
\begin{verbatim}
## [1] 3
\end{verbatim}
\begin{alltt}
\hlcom{####}
\hlcom{# Using a Random Forest}

\hlstd{cars.Forest} \hlkwb{<-} \hlkwd{randomForest}\hlstd{(}\hlkwd{as.factor}\hlstd{(am)} \hlopt{~} \hlstd{mpg}\hlopt{+}\hlstd{cyl}\hlopt{+}\hlstd{disp}\hlopt{+}\hlstd{hp}\hlopt{+}\hlstd{drat}\hlopt{+}\hlstd{wt}\hlopt{+}\hlstd{qsec}\hlopt{+}\hlstd{vs}\hlopt{+}\hlstd{gear}\hlopt{+}\hlstd{carb,} \hlkwc{data}\hlstd{=training.data ,} \hlkwc{importance}\hlstd{=}\hlnum{TRUE}\hlstd{,}
                            \hlkwc{ntree}\hlstd{=}\hlnum{128}\hlstd{)}
\hlstd{prediction.Forest}\hlkwb{<-} \hlkwd{predict}\hlstd{(cars.Forest, test.data)}

\hlkwd{plot}\hlstd{(test.data}\hlopt{$}\hlstd{am)}
\hlkwd{points}\hlstd{(}\hlkwd{as.numeric}\hlstd{(prediction.Forest)}\hlopt{-}\hlnum{1}\hlstd{,}\hlkwc{col} \hlstd{=} \hlstr{'purple'}\hlstd{,} \hlkwc{pch} \hlstd{=} \hlstr{"."}\hlstd{)}
\hlkwd{legend}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{0.4}\hlstd{,} \hlkwc{legend}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"Actual"}\hlstd{,} \hlstr{"Predictions"}\hlstd{),}
       \hlkwc{col}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"black"}\hlstd{,} \hlstr{"purple"}\hlstd{),}\hlkwc{pch} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-3-3} 
\begin{kframe}\begin{alltt}
\hlstd{incorrect.predict.Forest} \hlkwb{=} \hlkwd{sum}\hlstd{(}\hlkwd{abs}\hlstd{((}\hlkwd{as.numeric}\hlstd{(prediction.Forest)} \hlopt{-} \hlnum{1}\hlstd{)} \hlopt{-} \hlstd{test.data}\hlopt{$}\hlstd{am)} \hlopt{>} \hlnum{.5}\hlstd{)}
\hlstd{incorrect.predict.Forest}
\end{alltt}
\begin{verbatim}
## [1] 3
\end{verbatim}
\end{kframe}
\end{knitrout}





\end{document}
